{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Toolbox + MCP (Restaurant Demo)\n",
    "\n",
    "This notebook shows how to run a local MCP server and call its tools with the Toolbox LangChain SDK and langchain-openai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408619a",
   "metadata": {},
   "source": [
    "## Setup (uv init + venv)\n",
    "\n",
    "```bash\n",
    "uv init\n",
    "uv venv\n",
    ".\\.venv\\Scripts\\activate\n",
    "uv add mcp toolbox-langchain langchain-openai langgraph python-dotenv\n",
    "```\n",
    "\n",
    "Create a `.env` file in this folder:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=...\n",
    "TOOLBOX_URL=http://127.0.0.1:5000\n",
    "ADMIN_TOKEN=admin-token\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7cae8",
   "metadata": {},
   "source": [
    "## Start the MCP server\n",
    "\n",
    "Run this in a separate terminal:\n",
    "\n",
    "```bash\n",
    "python server.py\n",
    "```\n",
    "\n",
    "The server listens on http://127.0.0.1:5000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab381a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80928d27",
   "metadata": {},
   "source": [
    "## Load tools (toolset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_langchain import ToolboxClient\n",
    "\n",
    "TOOLBOX_URL = \"http://127.0.0.1:5000\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json, text/event-stream\",\n",
    "}\n",
    "# https://github.com/modelcontextprotocol/python-sdk/issues/1641\n",
    "\n",
    "with ToolboxClient(TOOLBOX_URL, client_headers=headers) as toolbox:\n",
    "    tools = toolbox.load_toolset()\n",
    "    print([t.name for t in tools])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "    tools = await toolbox.aload_toolset()\n",
    "\n",
    "[tool.name for tool in tools]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2462f1e",
   "metadata": {},
   "source": [
    "## Use case 1: manual tool calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274609fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "    list_prices = toolbox.load_tool(\"list_pizza_prices\")\n",
    "    get_price = toolbox.load_tool(\"get_pizza_price\")\n",
    "    get_hours = toolbox.load_tool(\"get_opening_hours\")\n",
    "\n",
    "    prices = list_prices.invoke({})\n",
    "    margherita = get_price.invoke({\"pizza\": \"margherita\"})\n",
    "    saturday = get_hours.invoke({\"day\": \"sat\"})\n",
    "\n",
    "prices, margherita, saturday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6115c",
   "metadata": {},
   "source": [
    "## Use case 3: LangChain + OpenAI (agent via LangGraph)\n",
    "\n",
    "This uses a small ReAct-style agent that can call the MCP tools automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "    tools = toolbox.load_toolset()\n",
    "    agent = create_agent(model, tools)\n",
    "\n",
    "    prompt = \"What are the pizza prices and the opening hours on Saturday?\"\n",
    "    result = agent.invoke({\"messages\": [(\"user\", prompt)]})\n",
    "    agent_answer = result[\"messages\"][-1].content\n",
    "\n",
    "agent_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd2d55",
   "metadata": {},
   "source": [
    "## Use case 4: LangChain + OpenAI (bind_tools)\n",
    "\n",
    "This binds the MCP tools to the model and runs tool calls manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "    tools = toolbox.load_toolset()\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    prompt = \"What are the pizza prices and the opening hours on Saturday?\"\n",
    "    first = model_with_tools.invoke(prompt)\n",
    "\n",
    "    if not first.tool_calls:\n",
    "        final_answer = first.content\n",
    "    else:\n",
    "        tool_messages = []\n",
    "        for call in first.tool_calls:\n",
    "            result = tool_map[call[\"name\"]].invoke(call[\"args\"])\n",
    "            tool_messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=call[\"id\"])\n",
    "            )\n",
    "\n",
    "        final = model_with_tools.invoke([(\"user\", prompt), first, *tool_messages])\n",
    "        final_answer = final.content\n",
    "\n",
    "final_answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainToolbox (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
