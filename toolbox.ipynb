{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Toolbox + MCP (Restaurant Demo)\n",
    "\n",
    "This notebook shows how to run a local MCP server and call its tools with the Toolbox LangChain SDK and langchain-openai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (uv init + venv)\n",
    "\n",
    "```bash\n",
    "uv init\n",
    "uv venv\n",
    ".\\.venv\\Scripts\\activate\n",
    "uv add mcp toolbox-langchain langchain-openai langgraph python-dotenv\n",
    "```\n",
    "\n",
    "Create a `.env` file in this folder:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=...\n",
    "TOOLBOX_URL=http://127.0.0.1:5000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the MCP server\n",
    "\n",
    "Run this in a separate terminal:\n",
    "\n",
    "```bash\n",
    "python server.py\n",
    "```\n",
    "\n",
    "The server listens on http://127.0.0.1:5000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "TOOLBOX_URL = os.getenv(\"TOOLBOX_URL\", \"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tools (toolset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list_pizza_prices',\n",
       " 'get_pizza_price',\n",
       " 'get_opening_hours',\n",
       " 'get_restaurant_info']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolbox_langchain import ToolboxClient\n",
    "\n",
    "async def load_tools():\n",
    "    async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "        return toolbox.load_toolset()\n",
    "\n",
    "tools = await load_tools()\n",
    "[tool.name for tool in tools]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1: manual tool calls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "    list_prices = toolbox.load_tool(\"list_pizza_prices\")\n",
    "    get_price = toolbox.load_tool(\"get_pizza_price\")\n",
    "    get_hours = toolbox.load_tool(\"get_opening_hours\")\n",
    "\n",
    "    prices = list_prices.invoke({})\n",
    "    margherita = get_price.invoke({\"pizza\": \"margherita\"})\n",
    "    saturday = get_hours.invoke({\"day\": \"sat\"})\n",
    "\n",
    "prices, margherita, saturday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 2: load a single tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"hours\": {\\n    \"mon\": \"11:00-22:00\",\\n    \"tue\": \"11:00-22:00\",\\n    \"wed\": \"11:00-22:00\",\\n    \"thu\": \"11:00-22:00\",\\n    \"fri\": \"11:00-23:00\",\\n    \"sat\": \"12:00-23:00\",\\n    \"sun\": \"12:00-21:00\"\\n  }\\n}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def load_single_tool():\n",
    "    async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "        get_hours = toolbox.load_tool(\"get_opening_hours\")\n",
    "        return get_hours.invoke({\"day\": \"all\"})\n",
    "\n",
    "all_hours = await load_single_tool()\n",
    "all_hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 3: LangChain + OpenAI (agent via LangGraph)\n",
    "\n",
    "This uses a small ReAct-style agent that can call the MCP tools automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_react_agent' from 'langchain' (c:\\Users\\User\\Desktop\\LangChainToolbox\\.venv\\Lib\\site-packages\\langchain\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[32m      4\u001b[39m model = ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_agent\u001b[39m():\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'create_react_agent' from 'langchain' (c:\\Users\\User\\Desktop\\LangChainToolbox\\.venv\\Lib\\site-packages\\langchain\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "async def run_agent():\n",
    "    async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "        tools = toolbox.load_toolset()\n",
    "        agent = create_agent(model, tools)\n",
    "\n",
    "        prompt = \"What are the pizza prices and the opening hours on Saturday?\"\n",
    "        result = agent.invoke({\"messages\": [(\"user\", prompt)]})\n",
    "        return result[\"messages\"][-1].content\n",
    "\n",
    "await run_agent()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 4: LangChain + OpenAI (bind_tools)\n",
    "\n",
    "This binds the MCP tools to the model and runs tool calls manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "async def run_with_bind_tools():\n",
    "    async with ToolboxClient(TOOLBOX_URL) as toolbox:\n",
    "        tools = toolbox.load_toolset()\n",
    "        tool_map = {tool.name: tool for tool in tools}\n",
    "        model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "        prompt = \"What are the pizza prices and the opening hours on Saturday?\"\n",
    "        first = model_with_tools.invoke(prompt)\n",
    "\n",
    "        if not first.tool_calls:\n",
    "            return first.content\n",
    "\n",
    "        tool_messages = []\n",
    "        for call in first.tool_calls:\n",
    "            result = tool_map[call[\"name\"]].invoke(call[\"args\"])\n",
    "            tool_messages.append(\n",
    "                ToolMessage(content=str(result), tool_call_id=call[\"id\"])\n",
    "            )\n",
    "\n",
    "        final = model_with_tools.invoke([(\"user\", prompt), first, *tool_messages])\n",
    "        return final.content\n",
    "\n",
    "await run_with_bind_tools()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChainToolbox (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
